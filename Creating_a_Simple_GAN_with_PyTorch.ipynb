{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/LY5WxW/kr2ZwPeJ7NWBC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://ai.plainenglish.io/creating-a-simple-gan-with-pytorch-a8dadfb72251)"
      ],
      "metadata": {
        "id": "p78cIsB0GVl9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dukZZNTAGD6v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurable variables\n",
        "NUM_EPOCHS = 50\n",
        "NOISE_DIMENSION = 50\n",
        "BATCH_SIZE = 128\n",
        "TRAIN_ON_GPU = True\n",
        "UNIQUE_RUN_ID = str(uuid.uuid4())\n",
        "PRINT_STATS_AFTER_BATCH = 50\n",
        "OPTIMIZER_LR = 0.0002\n",
        "OPTIMIZER_BETAS = (0.5, 0.999)\n",
        "GENERATOR_OUTPUT_IMAGE_SHAPE = 28 * 28 * 1"
      ],
      "metadata": {
        "id": "zqQXqfL1GbrK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speed ups\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "aqEPv8eLGdV4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"\n",
        "    Vanilla GAN Generator\n",
        "  \"\"\"\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      # First upsampling\n",
        "      nn.Linear(NOISE_DIMENSION, 128, bias=False),\n",
        "      nn.BatchNorm1d(128, 0.8),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      # Second upsampling\n",
        "      nn.Linear(128, 256, bias=False),\n",
        "      nn.BatchNorm1d(256, 0.8),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      # Third upsampling\n",
        "      nn.Linear(256, 512, bias=False),\n",
        "      nn.BatchNorm1d(512, 0.8),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      # Final upsampling\n",
        "      nn.Linear(512, GENERATOR_OUTPUT_IMAGE_SHAPE, bias=False),\n",
        "      nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Forward pass\"\"\"\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "NgCoMsDmGeZm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  \"\"\"\n",
        "    Vanilla GAN Discriminator\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(GENERATOR_OUTPUT_IMAGE_SHAPE, 1024),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      nn.Linear(512, 256),\n",
        "      nn.LeakyReLU(0.25),\n",
        "      nn.Linear(256, 1),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Forward pass\"\"\"\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "qEBmzYd9GjX0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "  \"\"\" Retrieve device based on settings and availability. \"\"\"\n",
        "  return torch.device(\"cuda:0\" if torch.cuda.is_available() and TRAIN_ON_GPU else \"cpu\")\n",
        "\n",
        "\n",
        "def make_directory_for_run():\n",
        "  \"\"\" Make a directory for this training run. \"\"\"\n",
        "  print(f'Preparing training run {UNIQUE_RUN_ID}')\n",
        "  if not os.path.exists('./runs'):\n",
        "    os.mkdir('./runs')\n",
        "  os.mkdir(f'./runs/{UNIQUE_RUN_ID}')\n",
        "\n",
        "\n",
        "def generate_image(generator, epoch = 0, batch = 0, device=get_device()):\n",
        "  \"\"\" Generate subplots with generated examples. \"\"\"\n",
        "  images = []\n",
        "  noise = generate_noise(BATCH_SIZE, device=device)\n",
        "  generator.eval()\n",
        "  images = generator(noise)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(16):\n",
        "    # Get image\n",
        "    image = images[i]\n",
        "    # Convert image back onto CPU and reshape\n",
        "    image = image.cpu().detach().numpy()\n",
        "    image = np.reshape(image, (28, 28))\n",
        "    # Plot\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "  if not os.path.exists(f'./runs/{UNIQUE_RUN_ID}/images'):\n",
        "    os.mkdir(f'./runs/{UNIQUE_RUN_ID}/images')\n",
        "  plt.savefig(f'./runs/{UNIQUE_RUN_ID}/images/epoch{epoch}_batch{batch}.jpg')\n",
        "\n",
        "\n",
        "def save_models(generator, discriminator, epoch):\n",
        "  \"\"\" Save models at specific point in time. \"\"\"\n",
        "  torch.save(generator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/generator_{epoch}.pth')\n",
        "  torch.save(discriminator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/discriminator_{epoch}.pth')\n",
        "\n",
        "\n",
        "def print_training_progress(batch, generator_loss, discriminator_loss):\n",
        "  \"\"\" Print training progress. \"\"\"\n",
        "  print('Losses after mini-batch %5d: generator %e, discriminator %e' %\n",
        "        (batch, generator_loss, discriminator_loss))"
      ],
      "metadata": {
        "id": "vrv-ob_cGkyi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset():\n",
        "  \"\"\" Prepare dataset through DataLoader \"\"\"\n",
        "  # Prepare MNIST dataset\n",
        "  dataset = MNIST(os.getcwd(), download=True, train=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "  ]))\n",
        "  # Batch and shuffle data with DataLoader\n",
        "  trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "  # Return dataset through DataLoader\n",
        "  return trainloader"
      ],
      "metadata": {
        "id": "ZS4YhY7KGmqS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_models(device = get_device()):\n",
        "  \"\"\" Initialize Generator and Discriminator models \"\"\"\n",
        "  generator = Generator()\n",
        "  discriminator = Discriminator()\n",
        "  # Move models to specific device\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "  # Return models\n",
        "  return generator, discriminator\n",
        "\n",
        "\n",
        "def initialize_loss():\n",
        "  \"\"\" Initialize loss function. \"\"\"\n",
        "  return nn.BCELoss()\n",
        "\n",
        "\n",
        "def initialize_optimizers(generator, discriminator):\n",
        "  \"\"\" Initialize optimizers for Generator and Discriminator. \"\"\"\n",
        "  generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
        "  discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
        "  return generator_optimizer, discriminator_optimizer"
      ],
      "metadata": {
        "id": "uMe4fEimGn1F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_noise(number_of_images = 1, noise_dimension = NOISE_DIMENSION, device=None):\n",
        "  \"\"\" Generate noise for number_of_images images, with a specific noise_dimension \"\"\"\n",
        "  return torch.randn(number_of_images, noise_dimension, device=device)\n",
        "\n",
        "\n",
        "def efficient_zero_grad(model):\n",
        "  \"\"\"\n",
        "    Apply zero_grad more efficiently\n",
        "    Source: https://betterprogramming.pub/how-to-make-your-pytorch-code-run-faster-93079f3c1f7b\n",
        "  \"\"\"\n",
        "  for param in model.parameters():\n",
        "    param.grad = None\n",
        "\n",
        "\n",
        "def forward_and_backward(model, data, loss_function, targets):\n",
        "  \"\"\"\n",
        "    Perform forward and backward pass in a generic way. Returns loss value.\n",
        "  \"\"\"\n",
        "  outputs = model(data)\n",
        "  error = loss_function(outputs, targets)\n",
        "  error.backward()\n",
        "  return error.item()"
      ],
      "metadata": {
        "id": "kTIymzUIGovK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_train_step(generator, discriminator, real_data, \\\n",
        "  loss_function, generator_optimizer, discriminator_optimizer, device = get_device()):\n",
        "  \"\"\" Perform a single training step. \"\"\"\n",
        "\n",
        "  # 1. PREPARATION\n",
        "  # Set real and fake labels.\n",
        "  real_label, fake_label = 1.0, 0.0\n",
        "  # Get images on CPU or GPU as configured and available\n",
        "  # Also set 'actual batch size', whih can be smaller than BATCH_SIZE\n",
        "  # in some cases.\n",
        "  real_images = real_data[0].to(device)\n",
        "  actual_batch_size = real_images.size(0)\n",
        "  label = torch.full((actual_batch_size,1), real_label, device=device)\n",
        "\n",
        "  # 2. TRAINING THE DISCRIMINATOR\n",
        "  # Zero the gradients for discriminator\n",
        "  efficient_zero_grad(discriminator)\n",
        "  # Forward + backward on real images, reshaped\n",
        "  real_images = real_images.view(real_images.size(0), -1)\n",
        "  error_real_images = forward_and_backward(discriminator, real_images, \\\n",
        "    loss_function, label)\n",
        "  # Forward + backward on generated images\n",
        "  noise = generate_noise(actual_batch_size, device=device)\n",
        "  generated_images = generator(noise)\n",
        "  label.fill_(fake_label)\n",
        "  error_generated_images =forward_and_backward(discriminator, \\\n",
        "    generated_images.detach(), loss_function, label)\n",
        "  # Optim for discriminator\n",
        "  discriminator_optimizer.step()\n",
        "\n",
        "  # 3. TRAINING THE GENERATOR\n",
        "  # Forward + backward + optim for generator, including zero grad\n",
        "  efficient_zero_grad(generator)\n",
        "  label.fill_(real_label)\n",
        "  error_generator = forward_and_backward(discriminator, generated_images, loss_function, label)\n",
        "  generator_optimizer.step()\n",
        "\n",
        "  # 4. COMPUTING RESULTS\n",
        "  # Compute loss values in floats for discriminator, which is joint loss.\n",
        "  error_discriminator = error_real_images + error_generated_images\n",
        "  # Return generator and discriminator loss so that it can be printed.\n",
        "  return error_generator, error_discriminator"
      ],
      "metadata": {
        "id": "a9cXZdD9Gqok"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
        "    generator_optimizer, discriminator_optimizer, epoch):\n",
        "  \"\"\" Perform a single epoch. \"\"\"\n",
        "  for batch_no, real_data in enumerate(dataloader, 0):\n",
        "    # Perform training step\n",
        "    generator_loss_val, discriminator_loss_val = perform_train_step(generator, \\\n",
        "      discriminator, real_data, loss_function, \\\n",
        "      generator_optimizer, discriminator_optimizer)\n",
        "    # Print statistics and generate image after every n-th batch\n",
        "    if batch_no % PRINT_STATS_AFTER_BATCH == 0:\n",
        "      print_training_progress(batch_no, generator_loss_val, discriminator_loss_val)\n",
        "      generate_image(generator, epoch, batch_no)\n",
        "  # Save models on epoch completion.\n",
        "  save_models(generator, discriminator, epoch)\n",
        "  # Clear memory after every epoch\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Bi4tZXffGsKd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dcgan():\n",
        "  \"\"\" Train the DCGAN. \"\"\"\n",
        "  # Make directory for unique run\n",
        "  make_directory_for_run()\n",
        "  # Set fixed random number seed\n",
        "  torch.manual_seed(42)\n",
        "  # Get prepared dataset\n",
        "  dataloader = prepare_dataset()\n",
        "  # Initialize models\n",
        "  generator, discriminator = initialize_models()\n",
        "  # Initialize loss and optimizers\n",
        "  loss_function = initialize_loss()\n",
        "  generator_optimizer, discriminator_optimizer = initialize_optimizers(generator, discriminator)\n",
        "  # Train the model\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print(f'Starting epoch {epoch}...')\n",
        "    perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
        "      generator_optimizer, discriminator_optimizer, epoch)\n",
        "  # Finished :-)\n",
        "  print(f'Finished unique run {UNIQUE_RUN_ID}')"
      ],
      "metadata": {
        "id": "pxj8EsUhGtUz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  train_dcgan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht8AJXIaGuZs",
        "outputId": "6a7975ac-243a-4f1f-9bc4-ec50623a0b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing training run 723dc40e-a37b-48bd-b523-47388bacca32\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 188543427.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-images-idx3-ubyte.gz to /content/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 9702498.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 49035659.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 18091670.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 0...\n",
            "Losses after mini-batch     0: generator 6.745945e-01, discriminator 1.373560e+00\n",
            "Losses after mini-batch    50: generator 9.920616e-01, discriminator 1.253178e+00\n",
            "Losses after mini-batch   100: generator 1.485789e+00, discriminator 6.659429e-01\n",
            "Losses after mini-batch   150: generator 1.764855e+00, discriminator 7.472023e-01\n",
            "Losses after mini-batch   200: generator 2.470916e+00, discriminator 1.424328e-01\n",
            "Losses after mini-batch   250: generator 2.470644e+00, discriminator 1.508455e-01\n",
            "Losses after mini-batch   300: generator 3.564474e+00, discriminator 2.906994e-01\n",
            "Losses after mini-batch   350: generator 4.120043e+00, discriminator 9.210491e-02\n",
            "Losses after mini-batch   400: generator 2.384119e+00, discriminator 6.042027e-01\n",
            "Losses after mini-batch   450: generator 5.699496e+00, discriminator 5.950879e-02\n",
            "Starting epoch 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 6.335404e+00, discriminator 8.357349e-02\n",
            "Losses after mini-batch    50: generator 1.721192e+00, discriminator 2.350930e-01\n",
            "Losses after mini-batch   100: generator 5.726129e+00, discriminator 1.058312e-01\n",
            "Losses after mini-batch   150: generator 6.235343e+00, discriminator 1.923165e-01\n",
            "Losses after mini-batch   200: generator 3.186408e+00, discriminator 1.028570e-01\n",
            "Losses after mini-batch   250: generator 4.889632e+00, discriminator 8.596821e-02\n",
            "Losses after mini-batch   300: generator 3.896846e+00, discriminator 2.364634e-01\n",
            "Losses after mini-batch   350: generator 3.443149e+00, discriminator 1.336587e-01\n",
            "Losses after mini-batch   400: generator 1.070976e+00, discriminator 1.710500e-01\n",
            "Losses after mini-batch   450: generator 4.101096e+00, discriminator 1.099221e-01\n",
            "Starting epoch 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 4.902669e+00, discriminator 7.081095e-02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e2850bcfb036>:20: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(10, 10))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch    50: generator 4.156384e+00, discriminator 1.484939e-01\n",
            "Losses after mini-batch   100: generator 3.832941e+00, discriminator 2.028659e-01\n",
            "Losses after mini-batch   150: generator 3.902554e+00, discriminator 9.672159e-02\n",
            "Losses after mini-batch   200: generator 4.300155e+00, discriminator 8.790184e-02\n",
            "Losses after mini-batch   250: generator 4.079717e+00, discriminator 9.815014e-02\n",
            "Losses after mini-batch   300: generator 3.927308e+00, discriminator 2.160270e-01\n",
            "Losses after mini-batch   350: generator 2.562116e+00, discriminator 2.885062e-01\n",
            "Losses after mini-batch   400: generator 3.541408e+00, discriminator 1.030426e-01\n",
            "Losses after mini-batch   450: generator 4.070016e+00, discriminator 1.939581e-01\n",
            "Starting epoch 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 3.746262e+00, discriminator 1.977436e-01\n",
            "Losses after mini-batch    50: generator 4.083234e+00, discriminator 9.283594e-02\n",
            "Losses after mini-batch   100: generator 3.639201e+00, discriminator 9.377757e-02\n",
            "Losses after mini-batch   150: generator 7.016272e+00, discriminator 5.674669e-01\n",
            "Losses after mini-batch   200: generator 3.935720e+00, discriminator 8.326766e-02\n",
            "Losses after mini-batch   250: generator 3.561923e+00, discriminator 1.071576e-01\n",
            "Losses after mini-batch   300: generator 4.966534e+00, discriminator 2.503906e-01\n",
            "Losses after mini-batch   350: generator 3.936877e+00, discriminator 1.321397e-01\n",
            "Losses after mini-batch   400: generator 8.731780e+00, discriminator 6.821875e-02\n",
            "Losses after mini-batch   450: generator 4.812022e+00, discriminator 2.889920e-01\n",
            "Starting epoch 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 6.241262e+00, discriminator 2.213090e-01\n",
            "Losses after mini-batch    50: generator 4.142720e+00, discriminator 2.973362e-01\n",
            "Losses after mini-batch   100: generator 1.151026e+01, discriminator 2.624960e+00\n",
            "Losses after mini-batch   150: generator 3.439471e+00, discriminator 1.528196e-01\n",
            "Losses after mini-batch   200: generator 4.971403e+00, discriminator 1.091337e-01\n",
            "Losses after mini-batch   250: generator 3.386770e+00, discriminator 1.690566e-01\n",
            "Losses after mini-batch   300: generator 3.591685e+00, discriminator 4.476184e-01\n",
            "Losses after mini-batch   350: generator 4.265957e+00, discriminator 1.647183e-01\n",
            "Losses after mini-batch   400: generator 5.256730e+00, discriminator 3.536374e-01\n",
            "Losses after mini-batch   450: generator 3.696630e+00, discriminator 7.871743e-02\n",
            "Starting epoch 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 4.702923e+00, discriminator 1.582158e-01\n",
            "Losses after mini-batch    50: generator 3.291218e+00, discriminator 1.312650e-01\n",
            "Losses after mini-batch   100: generator 6.126887e+00, discriminator 8.638979e-02\n",
            "Losses after mini-batch   150: generator 3.110704e+00, discriminator 1.009106e-01\n",
            "Losses after mini-batch   200: generator 5.789091e+00, discriminator 1.731698e-02\n",
            "Losses after mini-batch   250: generator 1.382945e+01, discriminator 9.242396e-01\n",
            "Losses after mini-batch   300: generator 4.534763e+00, discriminator 2.232216e-01\n",
            "Losses after mini-batch   350: generator 5.545297e+00, discriminator 3.201705e-02\n",
            "Losses after mini-batch   400: generator 4.609297e+00, discriminator 6.448760e-02\n",
            "Losses after mini-batch   450: generator 5.140736e+00, discriminator 4.807304e-02\n",
            "Starting epoch 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 4.698658e+00, discriminator 6.132881e-02\n",
            "Losses after mini-batch    50: generator 3.175646e+00, discriminator 1.808053e-01\n",
            "Losses after mini-batch   100: generator 8.681324e+00, discriminator 1.342313e+00\n",
            "Losses after mini-batch   150: generator 6.588618e+00, discriminator 2.027533e-01\n",
            "Losses after mini-batch   200: generator 3.070987e+00, discriminator 1.169706e-01\n",
            "Losses after mini-batch   250: generator 3.331106e+00, discriminator 1.521784e-01\n",
            "Losses after mini-batch   300: generator 3.708612e+00, discriminator 1.917658e-01\n",
            "Losses after mini-batch   350: generator 3.003156e+00, discriminator 1.729754e-01\n",
            "Losses after mini-batch   400: generator 2.439845e+00, discriminator 4.188347e-01\n",
            "Losses after mini-batch   450: generator 2.743575e+00, discriminator 1.194952e-01\n",
            "Starting epoch 7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 4.849981e+00, discriminator 5.661368e-02\n",
            "Losses after mini-batch    50: generator 3.780775e+00, discriminator 1.070675e-01\n",
            "Losses after mini-batch   100: generator 3.729255e+00, discriminator 1.238406e-01\n",
            "Losses after mini-batch   150: generator 3.700415e+00, discriminator 1.471189e-01\n",
            "Losses after mini-batch   200: generator 4.181446e+00, discriminator 1.364443e-01\n",
            "Losses after mini-batch   250: generator 3.313552e+00, discriminator 1.363279e-01\n",
            "Losses after mini-batch   300: generator 3.209275e+00, discriminator 2.309584e-01\n",
            "Losses after mini-batch   350: generator 4.014702e+00, discriminator 1.239275e-01\n",
            "Losses after mini-batch   400: generator 3.707943e+00, discriminator 1.222369e-01\n",
            "Losses after mini-batch   450: generator 3.037217e+00, discriminator 1.742500e-01\n",
            "Starting epoch 8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 3.028024e+00, discriminator 1.736146e-01\n",
            "Losses after mini-batch    50: generator 3.012970e+00, discriminator 1.486586e-01\n",
            "Losses after mini-batch   100: generator 2.904484e+00, discriminator 1.979996e-01\n",
            "Losses after mini-batch   150: generator 3.076577e+00, discriminator 1.550633e-01\n",
            "Losses after mini-batch   200: generator 4.138729e+00, discriminator 1.571399e-01\n",
            "Losses after mini-batch   250: generator 3.982795e+00, discriminator 1.742553e-01\n",
            "Losses after mini-batch   300: generator 2.955209e+00, discriminator 1.719607e-01\n",
            "Losses after mini-batch   350: generator 3.408131e+00, discriminator 2.196241e-01\n",
            "Losses after mini-batch   400: generator 9.517691e+00, discriminator 1.646822e+00\n",
            "Losses after mini-batch   450: generator 3.572849e+00, discriminator 7.375039e-01\n",
            "Starting epoch 9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.732055e+00, discriminator 2.668496e-01\n",
            "Losses after mini-batch    50: generator 2.528329e+00, discriminator 2.632331e-01\n",
            "Losses after mini-batch   100: generator 4.029795e+00, discriminator 3.385501e-01\n",
            "Losses after mini-batch   150: generator 2.852401e+00, discriminator 2.535363e-01\n",
            "Losses after mini-batch   200: generator 2.243791e+00, discriminator 2.163462e-01\n",
            "Losses after mini-batch   250: generator 2.258675e+00, discriminator 4.170284e-01\n",
            "Losses after mini-batch   300: generator 3.006543e+00, discriminator 2.136022e-01\n",
            "Losses after mini-batch   350: generator 2.904125e+00, discriminator 2.378773e-01\n",
            "Losses after mini-batch   400: generator 2.921909e+00, discriminator 3.324316e-01\n",
            "Losses after mini-batch   450: generator 3.253368e+00, discriminator 2.426025e-01\n",
            "Starting epoch 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.017276e+00, discriminator 3.591729e-01\n",
            "Losses after mini-batch    50: generator 2.414050e+00, discriminator 4.549744e-01\n",
            "Losses after mini-batch   100: generator 2.063195e+00, discriminator 3.536558e-01\n",
            "Losses after mini-batch   150: generator 1.668585e+00, discriminator 3.207829e-01\n",
            "Losses after mini-batch   200: generator 4.714922e+00, discriminator 3.565904e-01\n",
            "Losses after mini-batch   250: generator 3.303356e+00, discriminator 2.495268e-01\n",
            "Losses after mini-batch   300: generator 2.831855e+00, discriminator 1.896421e-01\n",
            "Losses after mini-batch   350: generator 2.720962e+00, discriminator 5.125599e-01\n",
            "Losses after mini-batch   400: generator 2.905859e+00, discriminator 3.285534e-01\n",
            "Losses after mini-batch   450: generator 3.257655e+00, discriminator 1.369362e-01\n",
            "Starting epoch 11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.135632e+00, discriminator 5.246011e-01\n",
            "Losses after mini-batch    50: generator 2.253667e+00, discriminator 2.838232e-01\n",
            "Losses after mini-batch   100: generator 2.663565e+00, discriminator 5.219621e-01\n",
            "Losses after mini-batch   150: generator 2.950775e+00, discriminator 3.994603e-01\n",
            "Losses after mini-batch   200: generator 2.493680e+00, discriminator 3.967535e-01\n",
            "Losses after mini-batch   250: generator 2.356967e+00, discriminator 3.556513e-01\n",
            "Losses after mini-batch   300: generator 2.282093e+00, discriminator 4.131092e-01\n",
            "Losses after mini-batch   350: generator 2.795115e+00, discriminator 2.633732e-01\n",
            "Losses after mini-batch   400: generator 3.399874e+00, discriminator 3.038701e-01\n",
            "Losses after mini-batch   450: generator 3.453903e+00, discriminator 4.028626e-01\n",
            "Starting epoch 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 1.893005e+00, discriminator 4.494428e-01\n",
            "Losses after mini-batch    50: generator 3.125241e+00, discriminator 2.550134e-01\n",
            "Losses after mini-batch   100: generator 2.728817e+00, discriminator 4.333142e-01\n",
            "Losses after mini-batch   150: generator 3.482103e+00, discriminator 2.832141e-01\n",
            "Losses after mini-batch   200: generator 2.155002e+00, discriminator 5.108024e-01\n",
            "Losses after mini-batch   250: generator 2.843810e+00, discriminator 3.101929e-01\n",
            "Losses after mini-batch   300: generator 2.559660e+00, discriminator 3.851557e-01\n",
            "Losses after mini-batch   350: generator 2.233145e+00, discriminator 4.435363e-01\n",
            "Losses after mini-batch   400: generator 3.566136e+00, discriminator 4.917183e-01\n",
            "Losses after mini-batch   450: generator 2.180484e+00, discriminator 3.748950e-01\n",
            "Starting epoch 13...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 3.094799e+00, discriminator 1.168689e+00\n",
            "Losses after mini-batch    50: generator 5.263699e+00, discriminator 6.090003e-01\n",
            "Losses after mini-batch   100: generator 2.083642e+00, discriminator 3.909005e-01\n",
            "Losses after mini-batch   150: generator 1.893088e+00, discriminator 1.000087e+00\n",
            "Losses after mini-batch   200: generator 2.436835e+00, discriminator 3.265450e-01\n",
            "Losses after mini-batch   250: generator 2.136750e+00, discriminator 3.995759e-01\n",
            "Losses after mini-batch   300: generator 2.332439e+00, discriminator 4.263988e-01\n",
            "Losses after mini-batch   350: generator 2.924539e+00, discriminator 3.917817e-01\n",
            "Losses after mini-batch   400: generator 2.287851e+00, discriminator 4.500417e-01\n",
            "Losses after mini-batch   450: generator 2.241320e+00, discriminator 3.933378e-01\n",
            "Starting epoch 14...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.006852e+00, discriminator 4.389461e-01\n",
            "Losses after mini-batch    50: generator 3.090936e+00, discriminator 3.290545e-01\n",
            "Losses after mini-batch   100: generator 2.700200e+00, discriminator 2.987646e-01\n",
            "Losses after mini-batch   150: generator 2.486693e+00, discriminator 4.774731e-01\n",
            "Losses after mini-batch   200: generator 2.311074e+00, discriminator 4.411272e-01\n",
            "Losses after mini-batch   250: generator 3.653743e+00, discriminator 3.630042e-01\n",
            "Losses after mini-batch   300: generator 3.194389e+00, discriminator 3.383802e-01\n",
            "Losses after mini-batch   350: generator 2.781307e+00, discriminator 3.935457e-01\n",
            "Losses after mini-batch   400: generator 3.452674e+00, discriminator 3.880996e-01\n",
            "Losses after mini-batch   450: generator 2.514356e+00, discriminator 3.316697e-01\n",
            "Starting epoch 15...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.969434e+00, discriminator 2.614698e-01\n",
            "Losses after mini-batch    50: generator 2.657878e+00, discriminator 2.978193e-01\n",
            "Losses after mini-batch   100: generator 2.796903e+00, discriminator 8.636078e-01\n",
            "Losses after mini-batch   150: generator 4.719682e+00, discriminator 5.567800e-01\n",
            "Losses after mini-batch   200: generator 5.765613e+00, discriminator 5.923071e-01\n",
            "Losses after mini-batch   250: generator 4.993873e+00, discriminator 5.286907e-01\n",
            "Losses after mini-batch   300: generator 1.985026e+00, discriminator 4.319179e-01\n",
            "Losses after mini-batch   350: generator 2.792216e+00, discriminator 3.986765e-01\n",
            "Losses after mini-batch   400: generator 2.744826e+00, discriminator 3.172485e-01\n",
            "Losses after mini-batch   450: generator 2.248590e+00, discriminator 3.878814e-01\n",
            "Starting epoch 16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.454536e+00, discriminator 3.985633e-01\n",
            "Losses after mini-batch    50: generator 2.441531e+00, discriminator 4.075067e-01\n",
            "Losses after mini-batch   100: generator 3.193110e+00, discriminator 3.147950e-01\n",
            "Losses after mini-batch   150: generator 1.382910e+00, discriminator 4.588699e-01\n",
            "Losses after mini-batch   200: generator 2.791405e+00, discriminator 3.540031e-01\n",
            "Losses after mini-batch   250: generator 2.284254e+00, discriminator 4.092522e-01\n",
            "Losses after mini-batch   300: generator 1.205188e+00, discriminator 6.384847e-01\n",
            "Losses after mini-batch   350: generator 3.423278e+00, discriminator 3.586063e-01\n",
            "Losses after mini-batch   400: generator 2.296422e+00, discriminator 4.028641e-01\n",
            "Losses after mini-batch   450: generator 2.459776e+00, discriminator 4.340618e-01\n",
            "Starting epoch 17...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.265193e+00, discriminator 3.375565e-01\n",
            "Losses after mini-batch    50: generator 1.902234e+00, discriminator 3.277797e-01\n",
            "Losses after mini-batch   100: generator 2.143736e+00, discriminator 4.458684e-01\n",
            "Losses after mini-batch   150: generator 1.851775e+00, discriminator 4.669338e-01\n",
            "Losses after mini-batch   200: generator 3.309391e+00, discriminator 4.197564e-01\n",
            "Losses after mini-batch   250: generator 1.984307e+00, discriminator 5.275269e-01\n",
            "Losses after mini-batch   300: generator 3.100890e+00, discriminator 3.138036e-01\n",
            "Losses after mini-batch   350: generator 3.444187e+00, discriminator 4.904771e-01\n",
            "Losses after mini-batch   400: generator 3.298169e+00, discriminator 3.825207e-01\n",
            "Losses after mini-batch   450: generator 2.301888e+00, discriminator 4.944170e-01\n",
            "Starting epoch 18...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.029324e+00, discriminator 5.632764e-01\n",
            "Losses after mini-batch    50: generator 2.805857e+00, discriminator 3.306401e-01\n",
            "Losses after mini-batch   100: generator 2.760609e+00, discriminator 4.351533e-01\n",
            "Losses after mini-batch   150: generator 1.259840e+00, discriminator 8.243903e-01\n",
            "Losses after mini-batch   200: generator 1.850014e+00, discriminator 3.605169e-01\n",
            "Losses after mini-batch   250: generator 2.499646e+00, discriminator 4.582369e-01\n",
            "Losses after mini-batch   300: generator 2.862460e+00, discriminator 3.865363e-01\n",
            "Losses after mini-batch   350: generator 2.191002e+00, discriminator 4.434517e-01\n",
            "Losses after mini-batch   400: generator 2.782732e+00, discriminator 5.513942e-01\n",
            "Losses after mini-batch   450: generator 2.692574e+00, discriminator 4.403369e-01\n",
            "Starting epoch 19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.030479e+00, discriminator 5.453545e-01\n",
            "Losses after mini-batch    50: generator 1.501655e+00, discriminator 4.968506e-01\n",
            "Losses after mini-batch   100: generator 2.790746e+00, discriminator 3.105700e-01\n",
            "Losses after mini-batch   150: generator 1.545992e+00, discriminator 5.209754e-01\n",
            "Losses after mini-batch   200: generator 2.249057e+00, discriminator 6.011188e-01\n",
            "Losses after mini-batch   250: generator 1.825341e+00, discriminator 5.468428e-01\n",
            "Losses after mini-batch   300: generator 2.469321e+00, discriminator 4.158729e-01\n",
            "Losses after mini-batch   350: generator 2.260774e+00, discriminator 4.092411e-01\n",
            "Losses after mini-batch   400: generator 3.315424e+00, discriminator 7.050574e-01\n",
            "Losses after mini-batch   450: generator 2.461214e+00, discriminator 4.476089e-01\n",
            "Starting epoch 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.731565e+00, discriminator 5.407046e-01\n",
            "Losses after mini-batch    50: generator 1.717055e+00, discriminator 5.657960e-01\n",
            "Losses after mini-batch   100: generator 2.289103e+00, discriminator 4.475152e-01\n",
            "Losses after mini-batch   150: generator 3.001658e+00, discriminator 5.346655e-01\n",
            "Losses after mini-batch   200: generator 1.733114e+00, discriminator 4.914417e-01\n",
            "Losses after mini-batch   250: generator 1.729208e+00, discriminator 5.692256e-01\n",
            "Losses after mini-batch   300: generator 2.168021e+00, discriminator 5.005340e-01\n",
            "Losses after mini-batch   350: generator 3.205353e+00, discriminator 6.980309e-01\n",
            "Losses after mini-batch   400: generator 1.945647e+00, discriminator 4.775234e-01\n",
            "Losses after mini-batch   450: generator 2.249741e+00, discriminator 5.512062e-01\n",
            "Starting epoch 21...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 1.844712e+00, discriminator 4.838227e-01\n",
            "Losses after mini-batch    50: generator 2.509604e+00, discriminator 4.564531e-01\n",
            "Losses after mini-batch   100: generator 2.057275e+00, discriminator 5.272789e-01\n",
            "Losses after mini-batch   150: generator 2.781908e+00, discriminator 4.985360e-01\n",
            "Losses after mini-batch   200: generator 2.235098e+00, discriminator 4.818523e-01\n",
            "Losses after mini-batch   250: generator 2.826722e+00, discriminator 4.564054e-01\n",
            "Losses after mini-batch   300: generator 2.500067e+00, discriminator 4.682537e-01\n",
            "Losses after mini-batch   350: generator 1.687981e+00, discriminator 5.393127e-01\n",
            "Losses after mini-batch   400: generator 3.644117e+00, discriminator 5.861467e-01\n",
            "Losses after mini-batch   450: generator 1.425676e+00, discriminator 5.812652e-01\n",
            "Starting epoch 22...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 1.769431e+00, discriminator 5.363263e-01\n",
            "Losses after mini-batch    50: generator 2.174481e+00, discriminator 5.932842e-01\n",
            "Losses after mini-batch   100: generator 1.970208e+00, discriminator 5.636302e-01\n",
            "Losses after mini-batch   150: generator 1.582965e+00, discriminator 6.849477e-01\n",
            "Losses after mini-batch   200: generator 3.465657e+00, discriminator 7.801396e-01\n",
            "Losses after mini-batch   250: generator 2.421015e+00, discriminator 4.834346e-01\n",
            "Losses after mini-batch   300: generator 1.754345e+00, discriminator 5.372169e-01\n",
            "Losses after mini-batch   350: generator 2.136045e+00, discriminator 4.061514e-01\n",
            "Losses after mini-batch   400: generator 1.908655e+00, discriminator 9.855709e-01\n",
            "Losses after mini-batch   450: generator 2.257305e+00, discriminator 5.741217e-01\n",
            "Starting epoch 23...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 1.649265e+00, discriminator 5.660279e-01\n",
            "Losses after mini-batch    50: generator 2.353850e+00, discriminator 5.355863e-01\n",
            "Losses after mini-batch   100: generator 3.520501e+00, discriminator 7.349195e-01\n",
            "Losses after mini-batch   150: generator 1.919013e+00, discriminator 5.543074e-01\n",
            "Losses after mini-batch   200: generator 1.949348e+00, discriminator 5.444565e-01\n",
            "Losses after mini-batch   250: generator 2.149227e+00, discriminator 4.737177e-01\n",
            "Losses after mini-batch   300: generator 2.302320e+00, discriminator 4.540953e-01\n",
            "Losses after mini-batch   350: generator 2.032038e+00, discriminator 5.602559e-01\n",
            "Losses after mini-batch   400: generator 3.197411e+00, discriminator 7.292565e-01\n",
            "Losses after mini-batch   450: generator 2.079912e+00, discriminator 7.256105e-01\n",
            "Starting epoch 24...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 2.219929e+00, discriminator 5.537490e-01\n",
            "Losses after mini-batch    50: generator 2.018539e+00, discriminator 5.366391e-01\n",
            "Losses after mini-batch   100: generator 2.129616e+00, discriminator 5.191164e-01\n",
            "Losses after mini-batch   150: generator 2.144993e+00, discriminator 5.204096e-01\n",
            "Losses after mini-batch   200: generator 2.180583e+00, discriminator 4.762217e-01\n",
            "Losses after mini-batch   250: generator 2.122640e+00, discriminator 4.890135e-01\n",
            "Losses after mini-batch   300: generator 1.390023e+00, discriminator 7.667171e-01\n",
            "Losses after mini-batch   350: generator 1.890593e+00, discriminator 5.986788e-01\n",
            "Losses after mini-batch   400: generator 2.041548e+00, discriminator 6.405707e-01\n",
            "Losses after mini-batch   450: generator 2.865585e+00, discriminator 6.664992e-01\n",
            "Starting epoch 25...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses after mini-batch     0: generator 1.798567e+00, discriminator 5.501670e-01\n",
            "Losses after mini-batch    50: generator 2.023478e+00, discriminator 6.091071e-01\n",
            "Losses after mini-batch   100: generator 1.737526e+00, discriminator 6.296528e-01\n",
            "Losses after mini-batch   150: generator 1.634503e+00, discriminator 6.537172e-01\n",
            "Losses after mini-batch   200: generator 2.186034e+00, discriminator 5.866722e-01\n",
            "Losses after mini-batch   250: generator 2.731947e+00, discriminator 6.016388e-01\n",
            "Losses after mini-batch   300: generator 2.078309e+00, discriminator 6.659133e-01\n",
            "Losses after mini-batch   350: generator 1.825902e+00, discriminator 6.986797e-01\n"
          ]
        }
      ]
    }
  ]
}